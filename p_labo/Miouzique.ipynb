{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79522291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Ouvrir le fichier h5\n",
    "file_path = 'chemin/vers/votre/fichier.h5'\n",
    "h5_file = h5py.File(file_path, 'r')\n",
    "\n",
    "# Accéder aux groupes de données\n",
    "analysis_group = h5_file['analysis']\n",
    "metadata_group = h5_file['metadata']\n",
    "\n",
    "# Extraire certaines caractéristiques\n",
    "chroma_features = analysis_group['segments_pitches'][:]\n",
    "mfccs = analysis_group['segments_timbre'][:]\n",
    "tempo = analysis_group['tempo'][()]\n",
    "key = analysis_group['key'][()]\n",
    "loudness = analysis_group['loudness'][()]\n",
    "# ... et ainsi de suite\n",
    "\n",
    "# Fermer le fichier h5\n",
    "h5_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d226fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Charger les données à partir du fichier h5\n",
    "file_path = 'chemin/vers/votre/fichier.h5'\n",
    "h5_file = h5py.File(file_path, 'r')\n",
    "segments_pitches = h5_file['analysis']['segments_pitches'][:]\n",
    "segments_timbre = h5_file['analysis']['segments_timbre'][:]\n",
    "loudness = h5_file['analysis']['loudness'][:]\n",
    "labels = h5_file['metadata']['genre'][:]  # Assurez-vous d'avoir les étiquettes de genre dans votre fichier\n",
    "\n",
    "# Fermer le fichier h5\n",
    "h5_file.close()\n",
    "\n",
    "# Prétraitement des données\n",
    "# Concaténer les caractéristiques segments_pitches et segments_timbre\n",
    "features = np.concatenate((segments_pitches, segments_timbre), axis=1)\n",
    "\n",
    "# Normalisation des caractéristiques\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Encodage des étiquettes de genre en nombres\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Création du modèle\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(features_scaled.shape[1],)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(len(label_encoder.classes_), activation='softmax')  # Couche de sortie\n",
    "])\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraînement du modèle\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Évaluation du modèle sur l'ensemble de test\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ee76b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Charger le modèle préalablement entraîné\n",
    "model = tf.keras.models.load_model('chemin/vers/votre/modele.h5')  # Remplacez par le chemin de votre modèle\n",
    "\n",
    "# Charger le fichier audio .wav\n",
    "wav_file = 'chemin/vers/votre/fichier.wav'  # Remplacez par le chemin de votre fichier .wav\n",
    "y, sr = librosa.load(wav_file)\n",
    "\n",
    "# Extraire les caractéristiques (segments_pitches et segments_timbre)\n",
    "chroma_features = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
    "segments_features = np.concatenate((chroma_features, mfccs), axis=1)\n",
    "\n",
    "# Normalisation des caractéristiques\n",
    "scaler = StandardScaler()\n",
    "segments_features_scaled = scaler.fit_transform(segments_features)\n",
    "\n",
    "# Faire une prédiction sur le modèle\n",
    "predicted_probs = model.predict(np.expand_dims(segments_features_scaled, axis=0))\n",
    "predicted_label_index = np.argmax(predicted_probs)\n",
    "confidence = predicted_probs[0][predicted_label_index]\n",
    "\n",
    "# Charger l'encodeur d'étiquettes\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = np.load('chemin/vers/votre/label_encoder.npy')  # Remplacez par le chemin de votre encodeur d'étiquettes\n",
    "\n",
    "# Obtenir le genre prédit\n",
    "predicted_genre = label_encoder.inverse_transform([predicted_label_index])[0]\n",
    "\n",
    "print(f'Predicted genre: {predicted_genre} (Confidence: {confidence:.2f})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5d115e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cea0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2519d2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3e230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2edd74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a635ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4cf433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d7d93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d610094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d35e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
